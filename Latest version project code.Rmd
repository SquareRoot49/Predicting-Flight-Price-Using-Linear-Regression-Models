---
title: "R code"
output: html_document
date: "2024-12-14"
---
Part 0: Load the dataset:
```{r}
# library(randomForest)
# library(FSelector)

library(readr)
Flight_Prices_India <- read_csv("/Users/apple/Desktop/Project of Linear Regression Models/Clean_Dataset.csv")

Flight_Prices_India <- Flight_Prices_India[, -c(1,3)] # first column simply counts the rows, so it is unnecessary
head(Flight_Prices_India)
```

Part 1: Load Necessary Packages
```{r}
library(ggplot2)
library(dplyr)
library(mgcv)
library(readr)
library(leaps)
library(glmnet)
library(caret)
library(FSelector)
```

Part 2: Descriptive Analysis of Dataset
```{r}
summary(Flight_Prices_India)

categorical.vars <- c("airline", "source_city", "departure_time", "stops", "arrival_time", "destination_city", "class")

tables <- list()

for (i in 1:length(categorical.vars)) {
  tables[[categorical.vars[i]]] <- table(Flight_Prices_India[[categorical.vars[i]]])
}

```

```{r}
str(Flight_Prices_India)
names(Flight_Prices_India)
## Do some descriptive analysis:
for (col_name in colnames(Flight_Prices_India)) {
  if (is.numeric(Flight_Prices_India[[col_name]])) {
    # Numerical variables: draw histogram
    p <- ggplot(Flight_Prices_India, aes_string(x = col_name)) +
      geom_histogram(bins = 10, fill = "blue", color = "black", alpha = 0.7) +
      ggtitle(paste("Histogram of", col_name)) +
      xlab(col_name) +
      ylab("Frequency") +
      theme_minimal()
   
    # Save the histograms
    ggsave(paste0("Histogram_", col_name, ".png"), plot = p, width = 8, height = 6)
  } else if (is.factor(Flight_Prices_India[[col_name]]) || is.character(Flight_Prices_India[[col_name]])) {
    # Categorical variables: draw histogram
    p <- ggplot(Flight_Prices_India, aes_string(x = col_name)) +
      geom_bar(fill = "green", color = "black", alpha = 0.7) +
      ggtitle(paste("Bar Chart of", col_name)) +
      xlab(col_name) +
      ylab("Count") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
   
    # Save the histogram
    ggsave(paste0("BarChart_", col_name, ".png"), plot = p, width = 8, height = 6)
  }
}

```

Part 3: Statistical Analysis

3.0 Training and Test Data
```{r}
set.seed(3)

dat.length <- nrow(Flight_Prices_India)
training.indices <- sample(1:dat.length, 0.7*dat.length)
training <- Flight_Prices_India[training.indices, ]
test <- setdiff(Flight_Prices_India, training)

library(caret)
cross.valid <- trainControl(method = "cv", number = 5)


```

```{r}
# Using Chi-Squared Feature Selection to choose categorical features:
critical_value <- qchisq(0.95, df = length(categorical.vars))
print(critical_value)

chi_scores <- chi.squared(price ~ airline  + source_city + departure_time + stops + arrival_time + destination_city + class, data = training)
print(chi_scores)

selected_features <- order(chi_scores$attr_importance, decreasing = TRUE)
selected_features
```
```{r}
# Using Mutual Information Feature Selection to choose categorical features:
mi_scores <- information.gain(price ~ airline  + source_city + departure_time + stops + arrival_time + destination_city + class, data = training)

print(mi_scores)
```


3.1 Multiple Linear Regression
```{r}
head(training)
# Using forward selection:

null_model <- lm(price ~ 1, data = training)

full_model <- lm(price ~ duration + days_left, data = training)

forward_model <- step(null_model,
                      scope = list(lower = null_model, upper = full_model),
                      direction = "forward")

summary(forward_model)
```

```{r}
# Using backward selection:

full_model <- lm(price ~ duration + days_left, data = training)

backward_model <- step(full_model, direction = "backward")

summary(backward_model)

```

```{r}
# Using best subset selection:

library(leaps)
best_subset <- regsubsets(price ~ duration + days_left, data = training, nbest = 2)
summary(best_subset)

summary_best <- summary(best_subset)
adjr2 <- summary_best$adjr2

best_model_index <- which.max(adjr2)
best_model <- summary_best$outmat[best_model_index, ]

print(best_model)
```

```{r}
linear_model <- train(
  price ~ duration + days_left + stops + class + airline,              
  data = training,            
  method = "lm",          
  trControl = cross.valid
)

print(summary(linear_model))
print(linear_model$results)

linear_pred <- predict(linear_model, newdata = test)

linear_mse <- mean((test$price - linear_pred)^2)

print(paste('MSE of Linear Regression Model:', linear_mse))
```

3.2 Polynomial Regression
```{r}
polynomial_model <- train(
  price ~ poly(duration, 5) + poly(days_left, 5) + stops + class + airline, 
  data = training,
  method = "lm",
  trControl = cross.valid)

print(summary(polynomial_model))
print(polynomial_model$results)

polynomial_pred <- predict(polynomial_model, newdata = test)

polynomial_mse <- mean((test$price - polynomial_pred)^2)

print(paste('MSE of Polynomial Regression Model:', polynomial_mse))
```

```{r}
## Ridge Model
training$stops <- relevel(factor(training$stops), ref = "one")
training$class <- relevel(factor(training$class), ref = "Business")
training$airline <- relevel(factor(training$airline), ref = "Air_India")



x_train <- model.matrix(price ~ duration + days_left + stops + class + airline, data = training)[, -1]
y_train <- training$price
x_test <- model.matrix(price ~ duration + days_left + stops + class + airline, data = test)[, -1]
y_test <- test$price




library(glmnet)
ridge_model <- cv.glmnet(x_train, y_train, alpha = 0, family = "gaussian", nfold = 10)

ridge_model$lambda.min

ridge_pred <- predict(ridge_model, s = ridge_model$lambda.min, newx = x_test)

ridge_mse <- mean((y_test - ridge_pred)^2)

ridge_coef <- coef(ridge_model, s = "lambda.min")
print(ridge_coef)
print(ridge_model)
print(paste('MSE of Ridge Model:', ridge_mse))
```



```{r}
# Ridge model for polynomial model
poly_formula <- as.formula("price ~ poly(duration, 5, raw = TRUE) + poly(days_left, 5, raw = TRUE)")
x_train <- model.matrix(poly_formula, data = training)
y_train <- training$price

x_test <- model.matrix(price ~ duration + days_left + stops + class + airline - 1, data = test)
y_test <- test$price



ridge_model <- cv.glmnet(x = x_train, y = y_train, alpha = 0, family = "gaussian")  # Ridge
ridge_lambda <- ridge_model$lambda.min  
ridge_coef <- coef(ridge_model, s = ridge_lambda) 
ridge_pred <- predict(ridge_model, s = ridge_model$lambda.min, newx = x_test)
ridge_mse <- mean((y_test - ridge_pred)^2)

ridge_coef <- coef(ridge_model, s = "lambda.min")
print(ridge_coef)
print(ridge_model)
print(paste('MSE of Ridge Model:', ridge_mse))
```

```{r}
## Lasso Model
lasso_model <- cv.glmnet(x_train, y_train, alpha = 1, family = "gaussian", nfolds = 10)

best_lambda <- lasso_model$lambda.min
print(paste("Optimal lambda:", best_lambda))

lasso_pred <- predict(lasso_model, s = lasso_model$lambda.min, newx = x_test)


lasso_coef <- coef(lasso_model, s = best_lambda)
print(lasso_coef)
lasso_mse <- mean((y_test - lasso_pred)^2)
print(lasso_model)
print(paste('MSE of Lasso Model:', lasso_mse))

```


```{r}
lasso_model <- glmnet(x_train, y_train, alpha = 1, lambda = seq(1, 100, by = 1))
lasso_pred <- predict(lasso_model, s = lasso_model$lambda.min, newx = x_test)



lasso_mse <- mean((y_test - lasso_pred)^2)
print(paste('MSE of Lasso Model:', lasso_mse))
```


```{r}
# GAM model
library(mgcv)
gam_model <- gam(price ~ s(duration) + s(days_left) + class + airline + stops,
                 data = training ,
                 family = gaussian(link = "identity"))

summary(gam_model)


## Test the model:
predicted_price <- predict(gam_model, newdata = test)

mse <- mean((predicted_price - test$price)^2)
print(paste("MSE of GAM model:", mse))
```
```{r}
par(mfrow=c(1, 2))
plot(gam_model, col="blue", se=T)
```


# Classification Tree
```{r}
# Classification Tree
# Load necessary packages
library(rpart)
library(rpart.plot)

training.aug <- training
test.aug <- test

# Convert numerical predictors into categorical predictors
median.duration <- median(Flight_Prices_India$duration)
training.aug$relative.dur <- ifelse(training.aug$duration > median.duration, "long", "short")
training.aug$relative.dur <- as.factor(training.aug$relative.dur)

test.aug$relative.dur <- ifelse(test.aug$days_left > median.duration, "long", "short")
test.aug$relative.dur <- as.factor(test.aug$relative.dur)

median.days.left <- median(Flight_Prices_India$days_left)
training.aug$booking.time <- ifelse(training.aug$days_left > median.days.left, "early", "late")
training.aug$booking.time <- as.factor(training.aug$booking.time)

test.aug$booking.time <- ifelse(test.aug$days_left > median.days.left, "early", "late")
test.aug$booking.time <- as.factor(test.aug$booking.time)

# Convert response to categorical variable
median.price <- median(Flight_Prices_India$price)
training.aug$price_class <- ifelse(training.aug$price > median.price, "high", "low")
training.aug$price_class <- as.factor(training.aug$price_class)

test.aug$price_class <- ifelse(test.aug$price > median.price, "high", "low")
test.aug$price_class <- as.factor(test.aug$price_class)

# Cross-validation model
control.tree <- trainControl(method = "cv", number = 5)
set.seed(3)

# Building a classification tree model
tree_model <- train(price_class ~ airline + class + relative.dur + stops + booking.time, 
                    data = training.aug, 
                    method = "rpart", 
                    tuneGrid = expand.grid(cp = seq(0.01, 0.1, by = 0.01)),
                    trControl = control.tree)
print(tree_model$bestTune)

# Visualize the tree
rpart.plot(tree_model$finalModel)

# Prediction test set
final.tree.model <- tree_model
predicted_classes <- predict(final.tree.model, newdata = test.aug, type = "raw") # causes error!

# Confusion matrix
library(caret)
conf_matrix <- confusionMatrix(predicted_classes, test.aug$price_class)
print(conf_matrix)

# Output classification accuracy
accuracy <- conf_matrix$overall["Accuracy"]
cat("Accuracy of Classification Tree Model:", accuracy, "\n")

```


```{r}
print(paste('MSE of Linear Regression Model:', linear_mse))
print(paste('MSE of Polynomial Regression Model:', polynomial_mse))
print(paste('MSE of Ridge Model:', ridge_mse))
print(paste('MSE of Lasso Model:', lasso_mse))
print(paste("MSE of GAM model:", mse))
```

